{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#pip install transformers datasets torch tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from github import Github\n",
    "\n",
    "# GitHub API Token (Generate from GitHub Developer Settings)\n",
    "GITHUB_TOKEN = \"your_github_token\"\n",
    "\n",
    "# Initialize GitHub API Client\n",
    "g = Github(GITHUB_TOKEN)\n",
    "\n",
    "# Search for Flutter repositories\n",
    "query = \"language:Dart flutter\"\n",
    "repos = g.search_repositories(query=query, sort=\"stars\", order=\"desc\")\n",
    "\n",
    "# Directory to save Dart files\n",
    "os.makedirs(\"flutter_dataset\", exist_ok=True)\n",
    "\n",
    "for repo in repos[:50]:  # Limit to 50 repositories\n",
    "    print(f\"Cloning: {repo.full_name}\")\n",
    "    try:\n",
    "        contents = repo.get_contents(\"\")\n",
    "        for file in contents:\n",
    "            if file.path.endswith(\".dart\"):\n",
    "                dart_code = requests.get(file.download_url).text\n",
    "                with open(f\"flutter_dataset/{file.name}\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(dart_code)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {repo.full_name}: {e}\")\n",
    "\n",
    "print(\"âœ… Flutter dataset collected!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-24T20:08:54.402367Z",
     "iopub.status.busy": "2025-02-24T20:08:54.402048Z",
     "iopub.status.idle": "2025-02-24T20:08:55.252593Z",
     "shell.execute_reply": "2025-02-24T20:08:55.251755Z",
     "shell.execute_reply.started": "2025-02-24T20:08:54.402345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"wraps/codegen-flutter-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(ds[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:22:01.795977Z",
     "iopub.status.busy": "2025-02-25T04:22:01.795667Z",
     "iopub.status.idle": "2025-02-25T04:22:04.821936Z",
     "shell.execute_reply": "2025-02-25T04:22:04.821052Z",
     "shell.execute_reply.started": "2025-02-25T04:22:01.795951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:22:05.400572Z",
     "iopub.status.busy": "2025-02-25T04:22:05.400151Z",
     "iopub.status.idle": "2025-02-25T04:22:05.404138Z",
     "shell.execute_reply": "2025-02-25T04:22:05.403275Z",
     "shell.execute_reply.started": "2025-02-25T04:22:05.400547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:22:08.754641Z",
     "iopub.status.busy": "2025-02-25T04:22:08.754315Z",
     "iopub.status.idle": "2025-02-25T04:30:17.438396Z",
     "shell.execute_reply": "2025-02-25T04:30:17.437507Z",
     "shell.execute_reply.started": "2025-02-25T04:22:08.754614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dda516cde434457935e735560aed147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931fd9b159d644019bd4499ca6773657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/703k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82385be73d244f0da0f7d18717f7d874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34e4c0be6b748e6874867838b4b689c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167c98df76264c0f8a657da0a4ae7b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004bcad3aec54f8d9ec43b7bdd20c792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73b5a5d8ea14f0e98621e9f39dddd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00002.parquet:   0%|          | 0.00/69.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c056d6f396de48898a8342a240d6974b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00002.parquet:   0%|          | 0.00/77.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1d5d7ca8094067bbf8cdb1224cc759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/149599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560e046a0fe44814990ecf61e400c44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/149599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aa051470714c86b22e373b6a853e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/149599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a tokenizer (CodeT5 is recommended for code-based tasks)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "def split_code(content):\n",
    "    \"\"\"\n",
    "    Splits Dart code near function headers.\n",
    "    Returns (input_part, output_part).\n",
    "    \"\"\"\n",
    "    lines = content.split(\"\\n\")\n",
    "    split_idx = None\n",
    "\n",
    "    # Find a suitable split point near function headers\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"{\" in line and \"(\" in line and \"class \" not in line:  # Rough function header detection\n",
    "            split_idx = i + 1\n",
    "            break\n",
    "\n",
    "    if split_idx is None or split_idx >= len(lines) - 1:\n",
    "        return content, \"\"  # No split found, use full content\n",
    "\n",
    "    input_part = \"\\n\".join(lines[:split_idx])\n",
    "    output_part = \"\\n\".join(lines[split_idx:])\n",
    "\n",
    "    return input_part, output_part\n",
    "\n",
    "def process_data(example):\n",
    "    \"\"\"\n",
    "    Process dataset to create input-output pairs for sequence-to-sequence learning.\n",
    "    \"\"\"\n",
    "    input_part, output_part = split_code(example[\"content\"])\n",
    "\n",
    "    # Tokenize input and output\n",
    "    input_encodings = tokenizer(input_part, padding=\"max_length\", truncation=True, max_length=512)\n",
    "    output_encodings = tokenizer(output_part, padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_encodings[\"input_ids\"],\n",
    "        \"attention_mask\": input_encodings[\"attention_mask\"],\n",
    "        \"decoder_input_ids\": output_encodings[\"input_ids\"][:-1],  # Shifted left\n",
    "        \"labels\": output_encodings[\"input_ids\"][1:],  # Shifted right\n",
    "    }\n",
    "\n",
    "# Load the dataset\n",
    "dataset =load_dataset(\"wraps/codegen-flutter-v1\")\n",
    "\n",
    "# Apply transformation\n",
    "processed_dataset = dataset[\"train\"].map(process_data, remove_columns=[\"repo_id\", \"file_path\", \"content\", \"__index_level_0__\"])\n",
    "\n",
    "# Save processed dataset\n",
    "processed_dataset.save_to_disk(\"processed_dart_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-25T04:21:40.497588Z",
     "iopub.status.idle": "2025-02-25T04:21:40.497903Z",
     "shell.execute_reply": "2025-02-25T04:21:40.497767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r /kaggle/working/processed_dart_dataset.zip /kaggle/working/processed_dart_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:30:17.440038Z",
     "iopub.status.busy": "2025-02-25T04:30:17.439621Z",
     "iopub.status.idle": "2025-02-25T04:30:17.519752Z",
     "shell.execute_reply": "2025-02-25T04:30:17.519010Z",
     "shell.execute_reply.started": "2025-02-25T04:30:17.440015Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ensure it's in the correct format\n",
    "tokenized_datasets = {\n",
    "    \"train\": processed_dataset.train_test_split(test_size=0.1)[\"train\"],\n",
    "    \"test\": processed_dataset.train_test_split(test_size=0.1)[\"test\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T04:31:51.707801Z",
     "iopub.status.busy": "2025-02-25T04:31:51.707507Z",
     "iopub.status.idle": "2025-02-25T11:51:36.468349Z",
     "shell.execute_reply": "2025-02-25T11:51:36.467623Z",
     "shell.execute_reply.started": "2025-02-25T04:31:51.707777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Salesforce--codet5-Small/snapshots/b1ee9570c289f21b5922b9c768a1ce12957bf968/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/CodeT5/pretrained_models/codet5_small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.47.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--Salesforce--codet5-Small/snapshots/b1ee9570c289f21b5922b9c768a1ce12957bf968/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at Salesforce/codet5-Small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using auto half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 134,639\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Training with DataParallel so batch size has been adjusted to: 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50,490\n",
      "  Number of trainable parameters = 60,492,288\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50490' max='50490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50490/50490 7:19:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.669300</td>\n",
       "      <td>0.586586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.534654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.460300</td>\n",
       "      <td>0.519799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14960\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./codeT5-flutter/checkpoint-16830\n",
      "Configuration saved in ./codeT5-flutter/checkpoint-16830/config.json\n",
      "Configuration saved in ./codeT5-flutter/checkpoint-16830/generation_config.json\n",
      "Model weights saved in ./codeT5-flutter/checkpoint-16830/model.safetensors\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14960\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./codeT5-flutter/checkpoint-33660\n",
      "Configuration saved in ./codeT5-flutter/checkpoint-33660/config.json\n",
      "Configuration saved in ./codeT5-flutter/checkpoint-33660/generation_config.json\n",
      "Model weights saved in ./codeT5-flutter/checkpoint-33660/model.safetensors\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to ./codeT5-flutter/checkpoint-50490\n",
      "Configuration saved in ./codeT5-flutter/checkpoint-50490/config.json\n",
      "Configuration saved in ./codeT5-flutter/checkpoint-50490/generation_config.json\n",
      "Model weights saved in ./codeT5-flutter/checkpoint-50490/model.safetensors\n",
      "Deleting older checkpoint [codeT5-flutter/checkpoint-16830] due to args.save_total_limit\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14960\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Saving model checkpoint to ./codeT5-flutter/checkpoint-50490\n",
      "Configuration saved in ./codeT5-flutter/checkpoint-50490/config.json\n",
      "Configuration saved in ./codeT5-flutter/checkpoint-50490/generation_config.json\n",
      "Model weights saved in ./codeT5-flutter/checkpoint-50490/model.safetensors\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Configuration saved in ./fine-tuned-codet5-flutter/config.json\n",
      "Configuration saved in ./fine-tuned-codet5-flutter/generation_config.json\n",
      "Model weights saved in ./fine-tuned-codet5-flutter/model.safetensors\n",
      "tokenizer config file saved in ./fine-tuned-codet5-flutter/tokenizer_config.json\n",
      "Special tokens file saved in ./fine-tuned-codet5-flutter/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-codet5-flutter/tokenizer_config.json',\n",
       " './fine-tuned-codet5-flutter/special_tokens_map.json',\n",
       " './fine-tuned-codet5-flutter/vocab.json',\n",
       " './fine-tuned-codet5-flutter/merges.txt',\n",
       " './fine-tuned-codet5-flutter/added_tokens.json',\n",
       " './fine-tuned-codet5-flutter/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "MODEL_NAME = \"Salesforce/codet5-Small\"\n",
    "\n",
    "# Load CodeT5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./codeT5-flutter\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    log_level=\"info\",\n",
    "    fp16=True,  # Enables mixed precision for speedup\n",
    "    dataloader_num_workers=4\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"]\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Save fine-tuned model\n",
    "model.save_pretrained(\"./fine-tuned-codet5-flutter\")\n",
    "tokenizer.save_pretrained(\"./fine-tuned-codet5-flutter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T11:52:49.181695Z",
     "iopub.status.busy": "2025-02-25T11:52:49.181405Z",
     "iopub.status.idle": "2025-02-25T11:54:02.143537Z",
     "shell.execute_reply": "2025-02-25T11:54:02.142669Z",
     "shell.execute_reply.started": "2025-02-25T11:52:49.181668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: kaggle/working/codeT5-flutter/ (stored 0%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/ (stored 0%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/model.safetensors (deflated 7%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/training_args.bin (deflated 52%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/optimizer.pt (deflated 8%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/scheduler.pt (deflated 56%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/generation_config.json (deflated 33%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/config.json (deflated 61%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/trainer_state.json (deflated 84%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-50490/rng_state.pth (deflated 25%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/ (stored 0%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/model.safetensors (deflated 7%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/training_args.bin (deflated 52%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/optimizer.pt (deflated 8%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/scheduler.pt (deflated 55%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/generation_config.json (deflated 33%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/config.json (deflated 61%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/trainer_state.json (deflated 84%)\n",
      "updating: kaggle/working/codeT5-flutter/checkpoint-33660/rng_state.pth (deflated 25%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /kaggle/working/codeT5-flutter.zip /kaggle/working/codeT5-flutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T11:57:24.030174Z",
     "iopub.status.busy": "2025-02-25T11:57:24.029845Z",
     "iopub.status.idle": "2025-02-25T11:57:36.768866Z",
     "shell.execute_reply": "2025-02-25T11:57:36.767816Z",
     "shell.execute_reply.started": "2025-02-25T11:57:24.030146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: kaggle/working/fine-tuned-codet5-flutter/ (stored 0%)\n",
      "updating: kaggle/working/fine-tuned-codet5-flutter/model.safetensors (deflated 7%)\n",
      "updating: kaggle/working/fine-tuned-codet5-flutter/vocab.json (deflated 59%)\n",
      "updating: kaggle/working/fine-tuned-codet5-flutter/tokenizer_config.json (deflated 94%)\n",
      "updating: kaggle/working/fine-tuned-codet5-flutter/generation_config.json (deflated 33%)\n",
      "updating: kaggle/working/fine-tuned-codet5-flutter/tokenizer.json (deflated 82%)\n",
      "updating: kaggle/working/fine-tuned-codet5-flutter/config.json (deflated 61%)\n",
      "updating: kaggle/working/fine-tuned-codet5-flutter/merges.txt (deflated 54%)\n",
      "updating: kaggle/working/fine-tuned-codet5-flutter/special_tokens_map.json (deflated 97%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /kaggle/working/fine-tuned-codet5-flutter.zip /kaggle/working/fine-tuned-codet5-flutter"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
